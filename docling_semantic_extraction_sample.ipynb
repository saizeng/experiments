{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb511bc",
   "metadata": {},
   "source": [
    "\n",
    "# Docling Semantic Extraction — Sample Notebook\n",
    "\n",
    "This notebook shows a **practical Docling pipeline** to extract **semantic groups** from PDFs (headings, paragraphs, lists, tables, figures/captions, etc.), and to export to Markdown/HTML/JSON for downstream use.\n",
    "\n",
    "> **Requirements**: Python 3.10+ recommended. Run the first cell to install packages in your own environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08a5d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If running on your own machine, uncomment and run this cell.\n",
    "# It installs Docling and optional OCR backends.\n",
    "# Note: Internet access is required for installation.\n",
    "# !pip install -U pip\n",
    "# !pip install docling\n",
    "# Optional OCR choices (choose one or more):\n",
    "# !pip install \"docling[easyocr]\"    # EasyOCR\n",
    "# !pip install \"docling[tesseract]\"  # Tesseract (requires Tesseract installed in OS)\n",
    "# !pip install \"docling[paddleocr]\"  # PaddleOCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69865f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Docling imports\n",
    "# Core converter\n",
    "from docling.document_converter import DocumentConverter\n",
    "# (Optional) PDF configuration helpers for custom pipelines\n",
    "# See https://docling-project.github.io/docling/examples/custom_convert/\n",
    "try:\n",
    "    from docling.datamodel.document import DoclingDocument\n",
    "except Exception as e:\n",
    "    # In case import fails before installation\n",
    "    print(\"Reminder: Install docling first. See the first cell.\")\n",
    "\n",
    "# Folder setup\n",
    "INPUT_DIR = Path(\"input_docs\")\n",
    "OUTPUT_DIR = Path(\"outputs\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Input folder: {INPUT_DIR.resolve()}\")\n",
    "print(f\"Output folder: {OUTPUT_DIR.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a4092e",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Quickstart — Convert a PDF\n",
    "\n",
    "Supply a **local file path** or a **URL** to `DocumentConverter().convert(...)`.\n",
    "\n",
    "The resulting `result.document` is a `DoclingDocument` you can export or traverse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb13aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to your PDF. Examples:\n",
    "# source = 'https://arxiv.org/pdf/2408.09869'  # URL (requires internet when running locally)\n",
    "# source = str(INPUT_DIR / 'sample.pdf')       # Local file\n",
    "source = str(INPUT_DIR / 'sample.pdf')  # <- replace with your PDF path\n",
    "\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(source)\n",
    "doc = result.document\n",
    "\n",
    "print(type(doc))\n",
    "print(\"Pages:\", len(doc.pages))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9823c5",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Export to Markdown / HTML / JSON\n",
    "\n",
    "Docling can export to common formats while preserving structure and reading order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e94d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "md_path = OUTPUT_DIR / 'document.md'\n",
    "html_path = OUTPUT_DIR / 'document.html'\n",
    "json_path = OUTPUT_DIR / 'document.json'\n",
    "\n",
    "# Markdown\n",
    "md_text = doc.export_to_markdown()\n",
    "md_path.write_text(md_text, encoding='utf-8')\n",
    "\n",
    "# HTML\n",
    "html_text = doc.export_to_html()\n",
    "html_path.write_text(html_text, encoding='utf-8')\n",
    "\n",
    "# JSON (rich structured output)\n",
    "doc_json = doc.as_dict()  # or doc.to_dict() depending on version\n",
    "json_path.write_text(json.dumps(doc_json, ensure_ascii=False, indent=2), encoding='utf-8')\n",
    "\n",
    "print(\"Wrote:\", md_path, html_path, json_path, sep=\"\\n- \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2390f7f",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Traverse Semantic Blocks\n",
    "\n",
    "Each page contains **blocks** (e.g., `heading`, `paragraph`, `list`, `table`, `figure`, `caption`, `footnote`).  \n",
    "Use these to build your own exporters or analytics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45993b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple traversal and preview of first N blocks per page\n",
    "N = 8\n",
    "for i, page in enumerate(doc.pages, start=1):\n",
    "    print(f\"\\n=== Page {i} ===\")\n",
    "    for b in page.blocks[:N]:\n",
    "        btype = getattr(b, \"type\", getattr(b, \"category\", \"block\"))\n",
    "        text = getattr(b, \"text\", \"\")\n",
    "        # Shorten for display\n",
    "        text_snippet = (text[:140] + \"…\") if len(text) > 140 else text\n",
    "        print(f\"- [{btype}] {text_snippet}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e644ff",
   "metadata": {},
   "source": [
    "\n",
    "### 3a) Headings and Lists\n",
    "\n",
    "You can filter blocks by type to extract headings for your ToC or list items for structured output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d5d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "headings = []\n",
    "list_items = []\n",
    "\n",
    "for page in doc.pages:\n",
    "    for b in page.blocks:\n",
    "        btype = getattr(b, \"type\", getattr(b, \"category\", \"\"))\n",
    "        if btype == \"heading\":\n",
    "            headings.append(getattr(b, \"text\", \"\"))\n",
    "        elif btype == \"list_item\" or btype == \"list\":\n",
    "            list_items.append(getattr(b, \"text\", \"\"))\n",
    "\n",
    "print(\"Headings found:\", len(headings))\n",
    "print(\"First 10 headings:\", headings[:10])\n",
    "print(\"\\nList items found:\", len(list_items))\n",
    "print(\"First 10 list items:\", list_items[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0536c197",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Tables — Preview and Export to CSV\n",
    "\n",
    "Docling parses **tables** (including cells). Below is a lightweight exporter that writes each table to CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "\n",
    "table_count = 0\n",
    "for page_idx, page in enumerate(doc.pages, start=1):\n",
    "    for block_idx, b in enumerate(page.blocks):\n",
    "        btype = getattr(b, \"type\", getattr(b, \"category\", \"\"))\n",
    "        if btype == \"table\":\n",
    "            table_count += 1\n",
    "            csv_path = OUTPUT_DIR / f\"table_p{page_idx}_{block_idx}.csv\"\n",
    "            # Docling tables usually have a rows/columns cell structure\n",
    "            rows = []\n",
    "            try:\n",
    "                for row in b.cells:  # depending on version: b.rows or b.cells\n",
    "                    rows.append([getattr(cell, \"text\", \"\") for cell in row])\n",
    "            except Exception:\n",
    "                # Fallback: if stored differently across versions\n",
    "                if hasattr(b, \"rows\"):\n",
    "                    for row in b.rows:\n",
    "                        rows.append([getattr(cell, \"text\", \"\") for cell in row])\n",
    "                else:\n",
    "                    rows = []\n",
    "\n",
    "            with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                for r in rows:\n",
    "                    writer.writerow(r)\n",
    "            print(\"Wrote table:\", csv_path)\n",
    "\n",
    "print(\"Total tables exported:\", table_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b0a00c",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Figures & Captions\n",
    "\n",
    "Extract figure images and their nearby captions for pairing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4398e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save figure images (if embedded/thumbnails are available in your Docling version)\n",
    "# and collect captions.\n",
    "captions = []\n",
    "\n",
    "IMG_DIR = OUTPUT_DIR / \"figures\"\n",
    "IMG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "fig_count = 0\n",
    "for page_idx, page in enumerate(doc.pages, start=1):\n",
    "    for block_idx, b in enumerate(page.blocks):\n",
    "        btype = getattr(b, \"type\", getattr(b, \"category\", \"\"))\n",
    "        if btype == \"caption\":\n",
    "            captions.append(getattr(b, \"text\", \"\"))\n",
    "        if btype == \"figure\":\n",
    "            fig_count += 1\n",
    "            # Depending on version, image bytes may be present; many times you use 'resources' from converter result.\n",
    "            # Here we only record placeholders and rely on exported HTML/Markdown for images.\n",
    "            print(f\"Figure found on page {page_idx}, block {block_idx}\")\n",
    "\n",
    "print(\"Captions found:\", len(captions))\n",
    "print(\"First 5 captions:\", captions[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4833aa",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Handling Scanned PDFs (OCR)\n",
    "\n",
    "To process scanned PDFs, enable an OCR backend in the converter’s PDF pipeline.  \n",
    "Below shows a minimal pattern — see **Docling’s custom conversion docs** for full options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6e7d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: toggling OCR in a custom conversion (pseudo-code; refer to docs for exact API in your version)\n",
    "# from docling.pipeline.standard_pdf_pipeline import StandardPdfPipeline\n",
    "# from docling.pipeline.ocr import OcrOptions, OcrEngine\n",
    "\n",
    "# ocr_opts = OcrOptions(engine=OcrEngine.PADDLE)  # or .EASYOCR / .TESSERACT\n",
    "# pipeline = StandardPdfPipeline(ocr_options=ocr_opts)\n",
    "\n",
    "# converter_ocr = DocumentConverter(pipeline=pipeline)\n",
    "# doc_ocr = converter_ocr.convert(source).document\n",
    "# print(\"OCR-enabled pages:\", len(doc_ocr.pages))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a096c27c",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Batch Conversion (Folder of PDFs)\n",
    "\n",
    "A small helper that converts all PDFs in a folder and writes Markdown/HTML/JSON outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ada5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_one(source_path: Path, out_dir: Path):\n",
    "    result = converter.convert(str(source_path))\n",
    "    d = result.document\n",
    "\n",
    "    md = d.export_to_markdown()\n",
    "    html = d.export_to_html()\n",
    "    js = d.as_dict()\n",
    "\n",
    "    stem = source_path.stem\n",
    "    (out_dir / f\"{stem}.md\").write_text(md, encoding=\"utf-8\")\n",
    "    (out_dir / f\"{stem}.html\").write_text(html, encoding=\"utf-8\")\n",
    "    (out_dir / f\"{stem}.json\").write_text(json.dumps(js, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    return d\n",
    "\n",
    "# Convert all PDFs in INPUT_DIR\n",
    "for pdf_path in sorted(INPUT_DIR.glob(\"*.pdf\")):\n",
    "    print(\"Converting:\", pdf_path.name)\n",
    "    _ = convert_one(pdf_path, OUTPUT_DIR)\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d0d782",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Minimal Semantic Chunking for RAG\n",
    "\n",
    "Create chunks by grouping adjacent blocks until a token/character budget is reached, while keeping headings as boundaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf02ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def iter_blocks(d):\n",
    "    for page in d.pages:\n",
    "        for b in page.blocks:\n",
    "            btype = getattr(b, \"type\", getattr(b, \"category\", \"\"))\n",
    "            text = getattr(b, \"text\", \"\")\n",
    "            yield btype, text\n",
    "\n",
    "def semantic_chunks(d, max_chars=1200):\n",
    "    chunks = []\n",
    "    buf = []\n",
    "    size = 0\n",
    "    for btype, text in iter_blocks(d):\n",
    "        if not text:\n",
    "            continue\n",
    "        # Start new chunk at headings\n",
    "        if btype == \"heading\" and buf:\n",
    "            chunks.append(\"\\n\".join(buf).strip())\n",
    "            buf, size = [], 0\n",
    "        if size + len(text) > max_chars and buf:\n",
    "            chunks.append(\"\\n\".join(buf).strip())\n",
    "            buf, size = [], 0\n",
    "        buf.append(text.strip())\n",
    "        size += len(text)\n",
    "    if buf:\n",
    "        chunks.append(\"\\n\".join(buf).strip())\n",
    "    return chunks\n",
    "\n",
    "chunks = semantic_chunks(doc, max_chars=1500)\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "print(\"\\nSample chunk:\\n\", chunks[0][:500], \"…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0089a854",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Notes\n",
    "- API names can evolve slightly between Docling versions. If an attribute is missing (e.g., `cells` vs `rows` on tables), check the official docs and adapt accordingly.\n",
    "- For advanced pipelines (OCR, page range, GPU, backends), see the **Custom Conversion** guide.\n",
    "\n",
    "Happy parsing!\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
