{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# PDF Region Classifier (5 types): Text, Table, Bar, Pie, Image\n", "\n", "This notebook detects **five** region types on a PDF page:\n", "- `text`\n", "- `table`\n", "- `bar_chart`\n", "- `pie_chart`\n", "- `image_other` (general image/figure)\n", "\n", "It uses both **vector-first** (pdfplumber/PyMuPDF) and **vision-first** (OpenCV) signals and fuses them into final regions.\n", "\n", "### Outputs\n", "- `regions_final.csv` \u2014 region bounding boxes + labels\n", "- `preview_final.png` \u2014 page image with annotated boxes\n", "- `crops/<label>_N.png` \u2014 cropped images for each detected region\n", "\n", "### Requirements\n", "- `pymupdf` (fitz) **or** `pdf2image` for rasterization\n", "- `opencv-python`, `numpy`, `pandas`\n", "- `pdfplumber` (recommended) for text/objects and optional tables\n", "- (optional) `camelot-py` for table extraction hints\n", "\n", "If some libraries are missing, the notebook will fall back to heuristics when possible."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 0) Install (run locally if needed)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# %%bash\n", "# pip install --upgrade pip\n", "# pip install pymupdf pdf2image opencv-python numpy pandas pdfplumber camelot-py matplotlib\n", "# # OS deps: poppler (for pdf2image), ghostscript (for camelot lattice), Java (for tabula if you choose)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1) Inputs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pathlib import Path\n", "\n", "PDF_PATH = Path('your_file.pdf')  # <-- set your PDF\n", "PAGE_INDEX = 0                    # 0-based\n", "DPI = 350\n", "OUT_DIR = Path('region_classifier_output')\n", "OUT_DIR.mkdir(parents=True, exist_ok=True)\n", "(PDF_PATH.resolve(), PAGE_INDEX, OUT_DIR.resolve())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2) Rasterize page to image (PyMuPDF preferred)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import importlib\n", "\n", "def page_to_image(pdf_path, page_index, out_dir, dpi=350):\n", "    if importlib.util.find_spec('fitz') is not None:\n", "        import fitz\n", "        doc = fitz.open(pdf_path)\n", "        page = doc[page_index]\n", "        mat = fitz.Matrix(dpi/72, dpi/72)\n", "        pix = page.get_pixmap(matrix=mat, alpha=False)\n", "        out = out_dir / f'page_{page_index+1:03d}.png'\n", "        pix.save(out.as_posix())\n", "        return out\n", "    elif importlib.util.find_spec('pdf2image') is not None:\n", "        from pdf2image import convert_from_path\n", "        imgs = convert_from_path(pdf_path, dpi=dpi, first_page=page_index+1, last_page=page_index+1)\n", "        out = out_dir / f'page_{page_index+1:03d}.png'\n", "        imgs[0].save(out)\n", "        return out\n", "    else:\n", "        raise RuntimeError('Install PyMuPDF or pdf2image to rasterize PDF pages.')\n", "\n", "PAGE_IMG = page_to_image(PDF_PATH, PAGE_INDEX, OUT_DIR, dpi=DPI)\n", "PAGE_IMG"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3) Collect vector hints (pdfplumber & PyMuPDF if available)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import importlib\n", "vector = {\n", "    'text_boxes': [],   # list of (x0,y0,x1,y1) in pixel coords\n", "    'image_boxes': [],  # embedded images in PDF\n", "    'rect_hits': None,  # heatmap for rectangles (bar hints)\n", "    'circ_hits': None,  # heatmap for circular-ish paths (pie hints)\n", "}\n", "\n", "import cv2, numpy as np\n", "page_img = cv2.imread(str(PAGE_IMG))\n", "H, W = page_img.shape[:2]\n", "\n", "scale = DPI/72.0\n", "\n", "# pdfplumber text & images\n", "if importlib.util.find_spec('pdfplumber') is not None:\n", "    import pdfplumber\n", "    with pdfplumber.open(PDF_PATH) as pdf:\n", "        page = pdf.pages[PAGE_INDEX]\n", "        words = page.extract_words(use_text_flow=True) or []\n", "        # Merge words into line boxes\n", "        lines = {}\n", "        for w in words:\n", "            yc = (w['top'] + w['bottom'])/2\n", "            key = round(yc/6)*6\n", "            lines.setdefault(key, []).append(w)\n", "        line_boxes = []\n", "        for _, ws in lines.items():\n", "            x0 = min(w['x0'] for w in ws); y0 = min(w['top'] for w in ws)\n", "            x1 = max(w['x1'] for w in ws); y1 = max(w['bottom'] for w in ws)\n", "            # convert PDF pts to pixels; pdfplumber origin top-left already\n", "            vector['text_boxes'].append((int(x0*scale), int(y0*scale), int(x1*scale), int(y1*scale)))\n", "        # Embedded images (figures)\n", "        for im in page.images:\n", "            x0,y0,x1,y1 = im['x0'], im['top'], im['x1'], im['bottom']\n", "            vector['image_boxes'].append((int(x0*scale), int(y0*scale), int(x1*scale), int(y1*scale)))\n", "\n", "# PyMuPDF drawings for rect/circle hints\n", "if importlib.util.find_spec('fitz') is not None:\n", "    import fitz\n", "    doc = fitz.open(PDF_PATH)\n", "    page = doc[PAGE_INDEX]\n", "    drawings = page.get_drawings()\n", "    rect_hits = np.zeros((H,W), dtype=np.uint8)\n", "    circ_hits = np.zeros_like(rect_hits)\n", "    for d in drawings:\n", "        for it in d['items']:\n", "            if it[0] == 'rect':\n", "                x0,y0,x1,y1 = it[1]\n", "                x0=int(x0*scale); y0=int(y0*scale); x1=int(x1*scale); y1=int(y1*scale)\n", "                x0=max(0,min(W-1,x0)); x1=max(0,min(W-1,x1))\n", "                y0=max(0,min(H-1,y0)); y1=max(0,min(H-1,y1))\n", "                rect_hits[y0:y1,x0:x1]=1\n", "            elif it[0] == 'curve':\n", "                pts = it[1]\n", "                xs=[p[0] for p in pts]; ys=[p[1] for p in pts]\n", "                x0=int(min(xs)*scale); x1=int(max(xs)*scale)\n", "                y0=int(min(ys)*scale); y1=int(max(ys)*scale)\n", "                x0=max(0,min(W-1,x0)); x1=max(0,min(W-1,x1))\n", "                y0=max(0,min(H-1,y0)); y1=max(0,min(H-1,y1))\n", "                circ_hits[y0:y1,x0:x1]=1\n", "    vector['rect_hits'] = rect_hits\n", "    vector['circ_hits'] = circ_hits\n", "\n", "len(vector['text_boxes']), len(vector['image_boxes'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4) Vision-first region proposals (non-text graphics)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import cv2, numpy as np\n", "gray = cv2.cvtColor(page_img, cv2.COLOR_BGR2GRAY)\n", "edges = cv2.Canny(gray, 50, 150)\n", "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n", "dilated = cv2.dilate(edges, kernel, iterations=2)\n", "cnts,_ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n", "candidates=[]\n", "for c in cnts:\n", "    x,y,w,h = cv2.boundingRect(c)\n", "    area=w*h\n", "    if area>8000 and w>60 and h>60 and w<W*0.98 and h<H*0.98:\n", "        candidates.append((x,y,w,h))\n", "\n", "def merge_boxes_xyxy(boxes, pad=8):\n", "    if not boxes: return []\n", "    boxes = [ (x-pad,y-pad,x+w+pad,y+h+pad) for (x,y,w,h) in sorted(boxes) ]\n", "    changed=True\n", "    while changed:\n", "        changed=False\n", "        new=[]\n", "        while boxes:\n", "            a = boxes.pop(0)\n", "            ax0,ay0,ax1,ay1=a\n", "            merged=False\n", "            for i,b in enumerate(boxes):\n", "                bx0,by0,bx1,by1=b\n", "                if not (ax1<bx0 or bx1<ax0 or ay1<by0 or by1<ay0):\n", "                    a=(min(ax0,bx0),min(ay0,by0),max(ax1,bx1),max(ay1,by1))\n", "                    boxes.pop(i)\n", "                    changed=True\n", "                    merged=True\n", "                    break\n", "            new.append(a)\n", "        boxes=new\n", "    # clip\n", "    out=[]\n", "    for (x0,y0,x1,y1) in boxes:\n", "        out.append((max(0,x0),max(0,y0),min(W-1,x1),min(H-1,y1)))\n", "    return out\n", "\n", "regions_img = merge_boxes_xyxy(candidates)\n", "len(regions_img), regions_img[:5]\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5) Classifiers: table, bar, pie (vision heuristics) + text/image masks"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def detect_tables_mask(gray):\n", "    thr = cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n", "    horiz = 255-thr; vert = 255-thr\n", "    h_scale = max(10, W//60)\n", "    v_scale = max(10, H//60)\n", "    h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (h_scale,1))\n", "    v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,v_scale))\n", "    h_lines = cv2.morphologyEx(horiz, cv2.MORPH_OPEN, h_kernel)\n", "    v_lines = cv2.morphologyEx(vert,  cv2.MORPH_OPEN, v_kernel)\n", "    grid = cv2.bitwise_and(h_lines, v_lines)\n", "    return grid\n", "\n", "def bar_score(roi):\n", "    g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n", "    b = cv2.GaussianBlur(g,(3,3),0)\n", "    t = cv2.threshold(b,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n", "    if (t==0).sum()>(t==255).sum():\n", "        t = cv2.bitwise_not(t)\n", "    t = cv2.morphologyEx(t, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT,(3,3)), iterations=1)\n", "    cnts,_ = cv2.findContours(t, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n", "    bars=[]\n", "    for c in cnts:\n", "        x,y,w,h = cv2.boundingRect(c)\n", "        aspect = h/max(1.0,w); area=w*h\n", "        if aspect>1.3 and area>200 and h>20: bars.append((x,y,w,h))\n", "    if len(bars)<3: return 0.0, bars\n", "    import numpy as np\n", "    bottoms = [y+h for (x,y,w,h) in bars]\n", "    std_baseline = np.std(bottoms) if len(bottoms)>=2 else 999\n", "    return float(len(bars)/(1+std_baseline/5.0)), bars\n", "\n", "def pie_score(roi):\n", "    g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n", "    g = cv2.medianBlur(g, 5)\n", "    circles = cv2.HoughCircles(g, cv2.HOUGH_GRADIENT, dp=1.2, minDist=30, param1=120, param2=40, minRadius=20, maxRadius=0)\n", "    if circles is None: return 0.0, None, []\n", "    import numpy as np, math\n", "    c = max(np.uint16(np.around(circles))[0], key=lambda z: z[2])\n", "    cx,cy,r = int(c[0]), int(c[1]), int(c[2])\n", "    edges = cv2.Canny(g,60,180)\n", "    lines = cv2.HoughLinesP(edges,1, np.pi/180, threshold=60, minLineLength=int(r*0.6), maxLineGap=10)\n", "    radials=[]\n", "    if lines is not None:\n", "        for l in lines[:,0,:]:\n", "            x1,y1,x2,y2 = l\n", "            def dist_point_line(px,py,a,b):\n", "                import math\n", "                ax,ay=a; bx,by=b\n", "                lab=math.hypot(bx-ax,by-ay)\n", "                if lab==0: return math.hypot(px-ax,py-ay)\n", "                t=max(0,min(1,((px-ax)*(bx-ax)+(py-ay)*(by-ay))/(lab*lab)))\n", "                qx=ax+t*(bx-ax); qy=ay+t*(by-ay)\n", "                return math.hypot(px-qx,py-qy)\n", "            if dist_point_line(cx,cy,(x1,y1),(x2,y2))<r*0.08:\n", "                radials.append((x1,y1,x2,y2))\n", "    score = 1.0 + 0.3*len(radials)\n", "    return float(score), (cx,cy,r), radials\n", "\n", "table_mask = detect_tables_mask(gray)\n", "table_cnts,_ = cv2.findContours(table_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n", "table_regions = []\n", "for c in table_cnts:\n", "    x,y,w,h = cv2.boundingRect(c)\n", "    if w*h>5000 and w>80 and h>60:\n", "        table_regions.append((x,y,x+w,y+h))\n", "\n", "# Prepare text mask from vector text boxes if available\n", "text_mask = np.zeros((H,W), dtype=np.uint8)\n", "for (x0,y0,x1,y1) in vector.get('text_boxes', []):\n", "    cv2.rectangle(text_mask,(x0,y0),(x1,y1),255,-1)\n", "\n", "classifications = []\n", "for (x0,y0,x1,y1) in regions_img:\n", "    roi = page_img[y0:y1, x0:x1]\n", "    # Check overlap with table regions\n", "    is_table=False\n", "    for (tx0,ty0,tx1,ty1) in table_regions:\n", "        if not (x1<tx0 or tx1<x0 or y1<ty0 or ty1<y0):\n", "            inter_w = min(x1,tx1)-max(x0,tx0)\n", "            inter_h = min(y1,ty1)-max(y0,ty0)\n", "            if inter_w>10 and inter_h>10:\n", "                is_table=True; break\n", "    if is_table:\n", "        label='table'\n", "    else:\n", "        bs,_ = bar_score(roi)\n", "        ps,_,_ = pie_score(roi)\n", "        # Use vector hints to nudge decisions\n", "        rect_hits = vector.get('rect_hits')\n", "        circ_hits = vector.get('circ_hits')\n", "        rect_sum = int(rect_hits[y0:y1,x0:x1].sum()) if rect_hits is not None else 0\n", "        circ_sum = int(circ_hits[y0:y1,x0:x1].sum()) if circ_hits is not None else 0\n", "        # text coverage ratio\n", "        tm = text_mask[y0:y1,x0:x1]\n", "        text_ratio = tm.mean()/255.0 if tm.size>0 else 0.0\n", "        if text_ratio>0.3:\n", "            label='text'\n", "        else:\n", "            # decide bar vs pie with thresholds + vector hints\n", "            if ps >= max(1.2, bs*1.3) or (circ_sum>rect_sum and circ_sum>1000):\n", "                label='pie_chart'\n", "            elif bs >= max(1.0, ps*1.2) or (rect_sum>circ_sum and rect_sum>1000):\n", "                label='bar_chart'\n", "            else:\n", "                # image_other if it overlaps embedded images or none\n", "                label='image_other'\n", "    classifications.append({'x0':x0,'y0':y0,'x1':x1,'y1':y1,'w':x1-x0,'h':y1-y0,'label':label})\n", "\n", "import pandas as pd\n", "df = pd.DataFrame(classifications)\n", "CSV_PATH = OUT_DIR / 'regions_final.csv'\n", "df.to_csv(CSV_PATH, index=False)\n", "CSV_PATH, df['label'].value_counts().to_dict()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6) Save annotated preview and per-region crops"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["annot = page_img.copy()\n", "colors = {\n", "    'text': (255,0,0),        # blue in BGR? OpenCV uses BGR; choose distinct\n", "    'table': (0,255,255),     # yellow\n", "    'bar_chart': (0,255,0),   # green\n", "    'pie_chart': (0,165,255), # orange\n", "    'image_other': (0,0,255)  # red\n", "}\n", "for _,row in df.iterrows():\n", "    x0,y0,x1,y1 = int(row.x0),int(row.y0),int(row.x1),int(row.y1)\n", "    color = colors.get(row.label,(255,255,255))\n", "    cv2.rectangle(annot,(x0,y0),(x1,y1),color,2)\n", "    cv2.putText(annot,row.label,(x0,max(0,y0-5)),cv2.FONT_HERSHEY_SIMPLEX,0.6,color,2,cv2.LINE_AA)\n", "\n", "PREVIEW = OUT_DIR / 'preview_final.png'\n", "cv2.imwrite(PREVIEW.as_posix(), annot)\n", "\n", "# Save crops\n", "crop_dir = OUT_DIR / 'crops'\n", "crop_dir.mkdir(exist_ok=True)\n", "counts = {}\n", "for _,row in df.iterrows():\n", "    label = row.label\n", "    counts[label] = counts.get(label,0)+1\n", "    x0,y0,x1,y1 = map(int,(row.x0,row.y0,row.x1,row.y1))\n", "    roi = page_img[y0:y1, x0:x1]\n", "    outp = crop_dir / f'{label}_{counts[label]}.png'\n", "    cv2.imwrite(outp.as_posix(), roi)\n", "PREVIEW, crop_dir"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7) Notes & tuning\n", "- **Priority logic**: tables are identified by gridlines; text is recognized via vector text boxes if available; charts are classified by shape heuristics and nudged by vector hints; remaining regions default to `image_other`.\n", "- If tables are missed, increase line kernel sizes in `detect_tables_mask`.\n", "- If text regions are over/under-detected, rely more/less on vector text boxes or add OCR-based text heatmaps.\n", "- Bar vs pie thresholds (`bar_score` / `pie_score`) can be tuned for your document style.\n", "- For multi-page processing, wrap the pipeline in a loop over page indices.\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}