{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Mixed PDF Page Extractor: Text + Tables + Bar Charts\n", "\n", "This notebook segments a PDF page into **text**, **table**, and **bar-chart** regions and extracts key info from each.\n", "\n", "### What you'll get\n", "- **Text regions** \u2192 TXT files\n", "- **Table regions** \u2192 CSV files\n", "- **Bar chart regions** \u2192 numeric CSV + recreated chart PNG\n", "- **(Optional) PPTX** summarizing the outputs\n", "\n", "### Strategies\n", "1. **Vector-first** (recommended):\n", "   - Use `pdfplumber`/`PyMuPDF` to get page objects, words, images, and lines.\n", "   - Detect **tables** with Camelot (lattice/stream) or `pdfplumber` table parser.\n", "   - Detect **figures/charts** via `page.images`/non-text vector regions; pass suspected charts to the bar-digitizer.\n", "2. **Vision-first** (fallback):\n", "   - Convert page \u2192 image, run OpenCV:\n", "     - **Tables**: detect gridlines (Hough/erosion) and cells \u2192 export to CSV.\n", "     - **Bar-charts**: find vertical bars and map pixel heights \u2192 values.\n", "     - **Text**: OCR within non-table/non-chart regions.\n", "\n", "You can run either or both, depending on your document.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 0) Install packages (run locally if missing)\n", "Uncomment the cell below and install packages in your local environment."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# %%bash\n", "# pip install --upgrade pip\n", "# pip install pymupdf pdfplumber camelot-py tabula-py opencv-python pytesseract pdf2image pandas numpy matplotlib python-pptx\n", "#\n", "# # OS dependencies:\n", "# # macOS: brew install tesseract ghostscript\n", "# # Ubuntu/Debian: sudo apt-get update && sudo apt-get install -y tesseract-ocr poppler-utils ghostscript default-jre\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1) Set inputs and output directory\n", "- Provide the PDF path, page index, and an output directory.\n", "- Choose DPI for rasterization.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pathlib import Path\n", "\n", "PDF_PATH = Path('your_file.pdf')   # <-- change this to your PDF\n", "PAGE_INDEX = 0                     # 0-based page index\n", "OUT_DIR = Path('mixed_pdf_output')\n", "DPI = 400\n", "\n", "OUT_DIR.mkdir(parents=True, exist_ok=True)\n", "print('PDF:', PDF_PATH.resolve())\n", "print('Page:', PAGE_INDEX+1)\n", "print('OUT_DIR:', OUT_DIR.resolve())\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2) Convert the target page to an image (for Vision-first path)\n", "Uses PyMuPDF (`fitz`) if available, otherwise pdf2image."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import importlib\n", "def page_to_image(pdf_path, page_index, out_dir, dpi=400):\n", "    if importlib.util.find_spec('fitz') is not None:\n", "        import fitz\n", "        doc = fitz.open(pdf_path)\n", "        page = doc[page_index]\n", "        mat = fitz.Matrix(dpi/72, dpi/72)\n", "        pix = page.get_pixmap(matrix=mat, alpha=False)\n", "        out = out_dir / f'page_{page_index+1:03d}.png'\n", "        pix.save(out.as_posix())\n", "        return out\n", "    elif importlib.util.find_spec('pdf2image') is not None:\n", "        from pdf2image import convert_from_path\n", "        imgs = convert_from_path(pdf_path, dpi=dpi, first_page=page_index+1, last_page=page_index+1)\n", "        out = out_dir / f'page_{page_index+1:03d}.png'\n", "        imgs[0].save(out)\n", "        return out\n", "    else:\n", "        raise RuntimeError('Install PyMuPDF or pdf2image to rasterize PDF pages.')\n", "\n", "PAGE_IMG = page_to_image(PDF_PATH, PAGE_INDEX, OUT_DIR, dpi=DPI)\n", "PAGE_IMG"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3A) Vector-first segmentation (objects from pdfplumber)\n", "We try to identify **tables**, **images (figures/charts)**, and text regions directly from the PDF.\n", "- Tables: try `camelot` (lattice/stream) on the page. If not available or fails, try `pdfplumber` tables.\n", "- Figures/charts: `page.images` + non-text vector regions.\n", "- Text: `page.extract_words()` grouped into blocks.\n", "\n", "This section saves candidate regions with bounding boxes for further processing.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import importlib, json\n", "from dataclasses import dataclass\n", "\n", "@dataclass\n", "class Region:\n", "    kind: str  # 'text' | 'table' | 'figure'\n", "    bbox: tuple  # (x0,y0,x1,y1) in PDF coordinate space\n", "    meta: dict\n", "\n", "regions = []\n", "\n", "if importlib.util.find_spec('pdfplumber') is None:\n", "    print('pdfplumber not installed, skipping vector-first. Install to enable.')\n", "else:\n", "    import pdfplumber\n", "    with pdfplumber.open(PDF_PATH) as pdf:\n", "        page = pdf.pages[PAGE_INDEX]\n", "        # 1) Candidate figures from embedded images\n", "        for im in page.images:\n", "            bbox = (im['x0'], im['top'], im['x1'], im['bottom'])\n", "            regions.append(Region('figure', bbox, {'source': 'image'}))\n", "\n", "        # 2) Text regions: group words by proximity (simple heuristic)\n", "        words = page.extract_words(use_text_flow=True)\n", "        # If words empty, skip\n", "        if words:\n", "            # Simple block merging: expand a running bbox for contiguous words by y-line proximity\n", "            lines = {}\n", "            for w in words:\n", "                y_center = (w['top'] + w['bottom'])/2\n", "                key = round(y_center/6)*6  # bin by approx 6 pts\n", "                lines.setdefault(key, []).append(w)\n", "            # merge lines into blocks by vertical gaps\n", "            line_boxes = []\n", "            for _, ws in lines.items():\n", "                xs0 = min(w['x0'] for w in ws); ys0 = min(w['top'] for w in ws)\n", "                xs1 = max(w['x1'] for w in ws); ys1 = max(w['bottom'] for w in ws)\n", "                line_boxes.append([xs0, ys0, xs1, ys1])\n", "            # merge nearby lines vertically\n", "            line_boxes.sort(key=lambda b: (b[1], b[0]))\n", "            merged = []\n", "            for b in line_boxes:\n", "                if not merged:\n", "                    merged.append(b)\n", "                else:\n", "                    a = merged[-1]\n", "                    # if vertical gap small and x-overlap reasonable, merge\n", "                    if b[1] - a[3] < 12 and not (b[0] > a[2] or b[2] < a[0]):\n", "                        a[0] = min(a[0], b[0]); a[1] = min(a[1], b[1])\n", "                        a[2] = max(a[2], b[2]); a[3] = max(a[3], b[3])\n", "                    else:\n", "                        merged.append(b)\n", "            for b in merged:\n", "                regions.append(Region('text', tuple(b), {'source': 'words'}))\n", "\n", "        # 3) Tables via Camelot (if available) else pdfplumber.extract_table\n", "        if importlib.util.find_spec('camelot') is not None:\n", "            import camelot\n", "            try:\n", "                t_stream = camelot.read_pdf(PDF_PATH.as_posix(), pages=str(PAGE_INDEX+1), flavor='stream')\n", "                for t in t_stream:\n", "                    b = t._bbox  # (x1, y1, x2, y2) Camelot coords from bottom-left\n", "                    # pdfplumber uses (x0, top, x1, bottom); convert if needed\n", "                    # Here we just store Camelot bbox in meta\n", "                    regions.append(Region('table', (b[0], b[1], b[2], b[3]), {'source': 'camelot_stream'}))\n", "            except Exception as e:\n", "                print('Camelot stream error:', e)\n", "            try:\n", "                t_lattice = camelot.read_pdf(PDF_PATH.as_posix(), pages=str(PAGE_INDEX+1), flavor='lattice')\n", "                for t in t_lattice:\n", "                    b = t._bbox\n", "                    regions.append(Region('table', (b[0], b[1], b[2], b[3]), {'source': 'camelot_lattice'}))\n", "            except Exception as e:\n", "                print('Camelot lattice error:', e)\n", "        else:\n", "            # Try pdfplumber's table finding via lines and words\n", "            try:\n", "                table_settings = {\n", "                    'vertical_strategy': 'lines',\n", "                    'horizontal_strategy': 'lines'\n", "                }\n", "                table = page.extract_table(table_settings)\n", "                # If any table found, mark page area heuristically (fallback: entire page)\n", "                if table:\n", "                    # Use page bbox as table region fallback\n", "                    regions.append(Region('table', (page.bbox[0], page.bbox[1], page.bbox[2], page.bbox[3]), {'source': 'pdfplumber_lines'}))\n", "            except Exception as e:\n", "                print('pdfplumber table finding error:', e)\n", "\n", "len(regions)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3B) Vision-first segmentation (OpenCV heuristics)\n", "We detect **tables** via gridlines and **bar charts** via vertical rectangles; remaining areas are likely **text**.\n", "This saves candidate region bounding boxes in image coordinates."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import cv2, numpy as np\n", "from PIL import Image\n", "\n", "img = cv2.imread(str(PAGE_IMG))\n", "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n", "thr = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n", "\n", "# --- Table detection via line morphology ---\n", "horiz = thr.copy(); vert = thr.copy()\n", "h_scale = max(10, thr.shape[1]//60)\n", "v_scale = max(10, thr.shape[0]//60)\n", "h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (h_scale,1))\n", "v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,v_scale))\n", "h_lines = cv2.morphologyEx(255 - horiz, cv2.MORPH_OPEN, h_kernel)\n", "v_lines = cv2.morphologyEx(255 - vert,  cv2.MORPH_OPEN, v_kernel)\n", "grid = cv2.bitwise_and(h_lines, v_lines)\n", "\n", "cnts,_ = cv2.findContours(grid, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n", "table_boxes = []\n", "for c in cnts:\n", "    x,y,w,h = cv2.boundingRect(c)\n", "    if w*h > 5000 and w>80 and h>60:\n", "        table_boxes.append((x,y,w,h))\n", "\n", "# --- Bar chart detection via tall rectangles ---\n", "blur = cv2.GaussianBlur(gray, (3,3), 0)\n", "bt = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n", "if (bt==0).sum() > (bt==255).sum():\n", "    bt = cv2.bitwise_not(bt)\n", "bt = cv2.morphologyEx(bt, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT,(3,3)), iterations=1)\n", "cnts,_ = cv2.findContours(bt, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n", "bar_boxes = []\n", "for c in cnts:\n", "    x,y,w,h = cv2.boundingRect(c)\n", "    aspect = h / max(1.0,w)\n", "    area = w*h\n", "    if aspect>1.5 and area>300 and h>30:\n", "        bar_boxes.append((x,y,w,h))\n", "\n", "# Merge bars that are close into a single chart region (convex hull bbox)\n", "def merge_boxes(boxes, pad=10):\n", "    if not boxes: return []\n", "    boxes = sorted(boxes)\n", "    merged = []\n", "    for (x,y,w,h) in boxes:\n", "        bx = (x-pad, y-pad, x+w+pad, y+h+pad)\n", "        if not merged:\n", "            merged.append(list(bx))\n", "        else:\n", "            a = merged[-1]\n", "            # if horizontally close/overlapping, merge\n", "            if bx[0] <= a[2] + 40 and not (bx[0]>a[2] or bx[2]<a[0]):\n", "                a[0]=min(a[0],bx[0]); a[1]=min(a[1],bx[1]); a[2]=max(a[2],bx[2]); a[3]=max(a[3],bx[3])\n", "            else:\n", "                merged.append(list(bx))\n", "    return [tuple(m) for m in merged]\n", "\n", "chart_regions_img = merge_boxes(bar_boxes)\n", "print('Table boxes (image coords):', table_boxes)\n", "print('Chart candidate regions (image coords):', chart_regions_img)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4) Extract text by region (vector-first or OCR fallback)\n", "We will:\n", "- Use `pdfplumber` (if available) to extract text blocks from the page using the vector regions gathered earlier; otherwise,\n", "- OCR the image, optionally restricting to non-table/non-chart areas.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["text_outputs = []\n", "import importlib\n", "if importlib.util.find_spec('pdfplumber') is not None:\n", "    import pdfplumber\n", "    with pdfplumber.open(PDF_PATH) as pdf:\n", "        page = pdf.pages[PAGE_INDEX]\n", "        texts = page.extract_text(x_tolerance=1.5, y_tolerance=2)\n", "        if texts:\n", "            fp = OUT_DIR / 'page_text_vector.txt'\n", "            with open(fp,'w',encoding='utf-8') as f:\n", "                f.write(texts)\n", "            text_outputs.append(fp)\n", "else:\n", "    print('pdfplumber not found; falling back to OCR for text.')\n", "    if importlib.util.find_spec('pytesseract') is not None:\n", "        import pytesseract, cv2\n", "        img = cv2.imread(str(PAGE_IMG))\n", "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n", "        gray = cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n", "        txt = pytesseract.image_to_string(gray)\n", "        fp = OUT_DIR / 'page_text_ocr.txt'\n", "        with open(fp,'w',encoding='utf-8') as f:\n", "            f.write(txt)\n", "        text_outputs.append(fp)\n", "    else:\n", "        print('pytesseract not installed; cannot OCR text.')\n", "\n", "text_outputs"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5) Extract tables to CSV\n", "Try **Camelot** first (stream & lattice), then **pdfplumber** table extraction. If vector extraction fails, we fallback to **Vision-first** grid-based extraction."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import importlib\n", "table_csvs = []\n", "if importlib.util.find_spec('camelot') is not None:\n", "    import camelot\n", "    try:\n", "        tables = camelot.read_pdf(PDF_PATH.as_posix(), pages=str(PAGE_INDEX+1), flavor='lattice')\n", "        for i,t in enumerate(tables):\n", "            fp = OUT_DIR / f'table_lattice_{i+1}.csv'\n", "            t.to_csv(fp.as_posix())\n", "            table_csvs.append(fp)\n", "    except Exception as e:\n", "        print('Camelot lattice failed:', e)\n", "    try:\n", "        tables = camelot.read_pdf(PDF_PATH.as_posix(), pages=str(PAGE_INDEX+1), flavor='stream')\n", "        for i,t in enumerate(tables):\n", "            fp = OUT_DIR / f'table_stream_{i+1}.csv'\n", "            t.to_csv(fp.as_posix())\n", "            table_csvs.append(fp)\n", "    except Exception as e:\n", "        print('Camelot stream failed:', e)\n", "\n", "if not table_csvs and importlib.util.find_spec('pdfplumber') is not None:\n", "    import pdfplumber, csv\n", "    with pdfplumber.open(PDF_PATH) as pdf:\n", "        page = pdf.pages[PAGE_INDEX]\n", "        try:\n", "            table = page.extract_table({'vertical_strategy':'lines','horizontal_strategy':'lines'})\n", "            if table:\n", "                fp = OUT_DIR / 'table_pdfplumber_lines.csv'\n", "                with open(fp,'w',newline='',encoding='utf-8') as f:\n", "                    writer = csv.writer(f)\n", "                    writer.writerows(table)\n", "                table_csvs.append(fp)\n", "        except Exception as e:\n", "            print('pdfplumber table failed:', e)\n", "\n", "if not table_csvs:\n", "    # Vision fallback: crop each detected table box and attempt OCR-based CSV (simple heuristic)\n", "    import cv2, pytesseract, csv\n", "    img = cv2.imread(str(PAGE_IMG))\n", "    for i,(x,y,w,h) in enumerate(table_boxes, start=1):\n", "        roi = img[y:y+h, x:x+w]\n", "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n", "        gray = cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n", "        data = pytesseract.image_to_data(gray, output_type=pytesseract.Output.DICT)\n", "        # naive row grouping by y\n", "        rows = {}\n", "        for j in range(len(data['text'])):\n", "            txt = data['text'][j].strip()\n", "            if not txt: continue\n", "            yy = data['top'][j]\n", "            key = round(yy/10)*10\n", "            rows.setdefault(key, []).append((data['left'][j], txt))\n", "        csv_rows = []\n", "        for _, cells in sorted(rows.items()):\n", "            line = [t for _,t in sorted(cells)]\n", "            csv_rows.append(line)\n", "        fp = OUT_DIR / f'table_vision_{i}.csv'\n", "        with open(fp,'w',newline='',encoding='utf-8') as f:\n", "            writer = csv.writer(f)\n", "            writer.writerows(csv_rows)\n", "        table_csvs.append(fp)\n", "\n", "table_csvs"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6) Extract bar-chart numbers from detected chart regions\n", "For each chart candidate region, we run bar detection and convert pixel heights \u2192 values.\n", "- You must provide a **y-axis mapping** for each region (baseline/top pixel and data min/max).\n", "- If the chart has tick labels, you can add OCR code to infer mapping automatically from two ticks."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import cv2, numpy as np, pandas as pd\n", "from PIL import Image\n", "\n", "# === Provide defaults; adjust per region ===\n", "YVAL_MIN = 0.0\n", "YVAL_MAX = 100.0\n", "\n", "def extract_bars_from_roi(roi_bgr, ypix_baseline, ypix_top, yval_min, yval_max, idx_prefix='chart'):\n", "    gray = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2GRAY)\n", "    blur = cv2.GaussianBlur(gray, (3,3), 0)\n", "    thr = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n", "    if (thr==0).sum() > (thr==255).sum():\n", "        thr = cv2.bitwise_not(thr)\n", "    thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT,(3,3)), iterations=1)\n", "    cnts,_ = cv2.findContours(thr, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n", "    bars=[]\n", "    for c in cnts:\n", "        x,y,w,h = cv2.boundingRect(c)\n", "        area=w*h; aspect = h/max(1.0,w)\n", "        if aspect>1.5 and area>300 and h>20:\n", "            bars.append((x,y,w,h))\n", "    bars = sorted(bars, key=lambda t: t[0])\n", "    span_pix = max(1, ypix_baseline - ypix_top)\n", "    def map_val(y_top):\n", "        r = (ypix_baseline - y_top)/span_pix\n", "        return yval_min + r*(yval_max - yval_min)\n", "    rows=[]\n", "    for i,(x,y,w,h) in enumerate(bars, start=1):\n", "        rows.append({'index': i, 'x': x, 'y_top': y, 'w': w, 'h_px': h, 'value': map_val(y)})\n", "    return pd.DataFrame(rows)\n", "\n", "chart_csvs = []\n", "img = cv2.imread(str(PAGE_IMG))\n", "for k,(x0,y0,x1,y1) in enumerate(chart_regions_img, start=1):\n", "    roi = img[y0:y1, x0:x1]\n", "    # TODO: set these per chart region (measure in the ROI image coordinates)\n", "    YPIX_BASELINE = int(0.9*(y1-y0))\n", "    YPIX_TOP      = int(0.1*(y1-y0))\n", "    df = extract_bars_from_roi(roi, YPIX_BASELINE, YPIX_TOP, YVAL_MIN, YVAL_MAX, idx_prefix=f'c{k}')\n", "    fp = OUT_DIR / f'chart_{k}_bars.csv'\n", "    df.to_csv(fp, index=False)\n", "    chart_csvs.append(fp)\n", "chart_csvs"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7) Recreate a bar chart from extracted CSV and save PNG\n", "Pick one of the `chart_*.csv` files and plot it."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd, matplotlib.pyplot as plt\n", "from pathlib import Path\n", "\n", "# Choose a chart CSV (change if needed)\n", "CHART_CSV = chart_csvs[0] if 'chart_csvs' in globals() and chart_csvs else None\n", "if CHART_CSV:\n", "    df = pd.read_csv(CHART_CSV)\n", "    plt.figure(figsize=(8,5))\n", "    plt.bar(df['index'].astype(str), df['value'].astype(float))\n", "    plt.ylabel('Value')\n", "    plt.title(CHART_CSV.name)\n", "    plt.tight_layout()\n", "    CHART_PNG = OUT_DIR / (Path(CHART_CSV).stem + '.png')\n", "    plt.savefig(CHART_PNG.as_posix(), dpi=200)\n", "    plt.show()\n", "    CHART_PNG\n", "else:\n", "    print('No chart CSVs produced yet. Adjust detection/mapping in Step 6 and re-run.')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 8) (Optional) Build a PPTX with extracts\n", "Creates a PowerPoint with:\n", "- Page text extract (first 2,000 chars)\n", "- First detected table CSV as a table\n", "- First chart PNG\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import importlib\n", "if importlib.util.find_spec('pptx') is None:\n", "    print('python-pptx not installed; skipping PPT build.')\n", "else:\n", "    from pptx import Presentation\n", "    from pptx.util import Inches\n", "    prs = Presentation()\n", "    # Title\n", "    slide = prs.slides.add_slide(prs.slide_layouts[0])\n", "    slide.shapes.title.text = 'PDF Mixed-Layout Extracts'\n", "    slide.placeholders[1].text = f'Page {PAGE_INDEX+1} from {PDF_PATH.name}'\n", "    # Text\n", "    if 'text_outputs' in globals() and text_outputs:\n", "        slide2 = prs.slides.add_slide(prs.slide_layouts[1])\n", "        slide2.shapes.title.text = 'Text Extract'\n", "        with open(text_outputs[0], 'r', encoding='utf-8') as f:\n", "            snippet = f.read()[:2000]\n", "        slide2.placeholders[1].text = snippet\n", "    # Table\n", "    if 'table_csvs' in globals() and table_csvs:\n", "        import pandas as pd\n", "        df = pd.read_csv(table_csvs[0], header=None)\n", "        slide3 = prs.slides.add_slide(prs.slide_layouts[6])\n", "        rows, cols = df.shape\n", "        table = slide3.shapes.add_table(rows+1, cols, Inches(0.5), Inches(1), Inches(9), Inches(5)).table\n", "        for j in range(cols):\n", "            table.cell(0,j).text = f'Col {j+1}'\n", "        for i in range(rows):\n", "            for j in range(cols):\n", "                table.cell(i+1,j).text = str(df.iat[i,j])\n", "    # Chart\n", "    if 'CHART_PNG' in globals() and CHART_PNG:\n", "        slide4 = prs.slides.add_slide(prs.slide_layouts[6])\n", "        slide4.shapes.add_picture(CHART_PNG.as_posix(), Inches(1), Inches(1), width=Inches(8))\n", "    PPTX_PATH = OUT_DIR / 'mixed_layout_summary.pptx'\n", "    prs.save(PPTX_PATH.as_posix())\n", "    PPTX_PATH\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 9) Next steps & tuning\n", "- If **tables** aren't detected:\n", "  - Try Camelot `flavor='stream'` vs `'lattice'`.\n", "  - Increase DPI and re-run.\n", "  - Tweak morphology kernel sizes in Step 3B.\n", "- If **bar charts** aren't detected:\n", "  - Adjust the aspect/area thresholds.\n", "  - Provide exact `YPIX_BASELINE` and `YPIX_TOP` (measure in the ROI) plus real `YVAL_MIN/MAX`.\n", "- If **text** is poor:\n", "  - Use vector text (pdfplumber) when possible.\n", "  - For OCR, try `--psm 6`/`--oem 1` configs and language packs.\n", "- For multi-series charts or stacked bars, segment by color and detect sub-rectangles (requires more OpenCV steps).\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}