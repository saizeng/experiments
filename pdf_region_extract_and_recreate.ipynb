{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# PDF Region \u2192 Extract \u2192 Recreate (Text \u2022 Table \u2022 Bar \u2022 Pie \u2022 Image)\n", "\n", "This notebook:\n", "1) **Detects** five region types on a PDF page: `text`, `table`, `bar_chart`, `pie_chart`, `image_other`.\n", "2) **Extracts** content from each region:\n", "   - Text \u2192 TXT\n", "   - Table \u2192 CSV\n", "   - Bar chart \u2192 values + optional x labels (OCR) + recreated chart (PNG)\n", "   - Pie chart \u2192 slice percentages (+ optional labels) + recreated chart (PNG)\n", "   - Images \u2192 PNG crops\n", "3) **Recreates** content and (optionally) builds a PPTX with everything.\n", "\n", "It uses both vector-first (pdfplumber/PyMuPDF) and computer-vision (OpenCV + OCR) approaches and falls back gracefully if a method isn't available.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 0) Install (run locally if missing)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# %%bash\n", "# pip install --upgrade pip\n", "# pip install pymupdf pdf2image opencv-python pdfplumber pytesseract pandas numpy matplotlib python-pptx camelot-py\n", "# # OS deps:\n", "# # macOS: brew install tesseract ghostscript poppler\n", "# # Ubuntu/Debian: sudo apt-get update && sudo apt-get install -y tesseract-ocr ghostscript poppler-utils default-jre\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1) Inputs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pathlib import Path\n", "\n", "PDF_PATH = Path('your_file.pdf')  # <-- set your PDF\n", "PAGE_INDEX = 0                    # 0-based page index\n", "DPI = 400\n", "OUT_DIR = Path('pdf_extract_recreate_output')\n", "OUT_DIR.mkdir(parents=True, exist_ok=True)\n", "PDF_PATH.resolve(), PAGE_INDEX, OUT_DIR.resolve()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2) Rasterize page (PyMuPDF preferred)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import importlib\n", "\n", "def page_to_image(pdf_path, page_index, out_dir, dpi=400):\n", "    if importlib.util.find_spec('fitz') is not None:\n", "        import fitz\n", "        doc = fitz.open(pdf_path)\n", "        page = doc[page_index]\n", "        mat = fitz.Matrix(dpi/72, dpi/72)\n", "        pix = page.get_pixmap(matrix=mat, alpha=False)\n", "        out = out_dir / f'page_{page_index+1:03d}.png'\n", "        pix.save(out.as_posix())\n", "        return out\n", "    elif importlib.util.find_spec('pdf2image') is not None:\n", "        from pdf2image import convert_from_path\n", "        imgs = convert_from_path(pdf_path, dpi=dpi, first_page=page_index+1, last_page=page_index+1)\n", "        out = out_dir / f'page_{page_index+1:03d}.png'\n", "        imgs[0].save(out)\n", "        return out\n", "    else:\n", "        raise RuntimeError('Install PyMuPDF or pdf2image to rasterize PDF pages.')\n", "\n", "PAGE_IMG = page_to_image(PDF_PATH, PAGE_INDEX, OUT_DIR, dpi=DPI)\n", "PAGE_IMG"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3) Collect vector hints (text boxes, embedded images, drawings)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import importlib, cv2, numpy as np\n", "page_bgr = cv2.imread(str(PAGE_IMG))\n", "H, W = page_bgr.shape[:2]\n", "scale = DPI/72.0\n", "\n", "vector = {'text_boxes':[], 'image_boxes':[], 'rect_hits':None, 'circ_hits':None}\n", "\n", "# pdfplumber text+images\n", "if importlib.util.find_spec('pdfplumber') is not None:\n", "    import pdfplumber\n", "    with pdfplumber.open(PDF_PATH) as pdf:\n", "        page = pdf.pages[PAGE_INDEX]\n", "        words = page.extract_words(use_text_flow=True) or []\n", "        lines = {}\n", "        for w in words:\n", "            yc = (w['top'] + w['bottom'])/2\n", "            key = round(yc/6)*6\n", "            lines.setdefault(key, []).append(w)\n", "        for _, ws in lines.items():\n", "            x0 = min(w['x0'] for w in ws); y0 = min(w['top'] for w in ws)\n", "            x1 = max(w['x1'] for w in ws); y1 = max(w['bottom'] for w in ws)\n", "            vector['text_boxes'].append((int(x0*scale), int(y0*scale), int(x1*scale), int(y1*scale)))\n", "        for im in page.images:\n", "            x0,y0,x1,y1 = im['x0'], im['top'], im['x1'], im['bottom']\n", "            vector['image_boxes'].append((int(x0*scale), int(y0*scale), int(x1*scale), int(y1*scale)))\n", "\n", "# PyMuPDF drawings\n", "if importlib.util.find_spec('fitz') is not None:\n", "    import fitz\n", "    doc = fitz.open(PDF_PATH)\n", "    page = doc[PAGE_INDEX]\n", "    drawings = page.get_drawings()\n", "    rect_hits = np.zeros((H,W), dtype=np.uint8)\n", "    circ_hits = np.zeros_like(rect_hits)\n", "    for d in drawings:\n", "        for it in d['items']:\n", "            if it[0]=='rect':\n", "                x0,y0,x1,y1 = it[1]\n", "                x0=int(x0*scale); x1=int(x1*scale)\n", "                y0=int(y0*scale); y1=int(y1*scale)\n", "                x0=max(0,min(W-1,x0)); x1=max(0,min(W-1,x1))\n", "                y0=max(0,min(H-1,y0)); y1=max(0,min(H-1,y1))\n", "                rect_hits[y0:y1,x0:x1]=1\n", "            elif it[0]=='curve':\n", "                pts = it[1]\n", "                xs=[p[0] for p in pts]; ys=[p[1] for p in pts]\n", "                x0=int(min(xs)*scale); x1=int(max(xs)*scale)\n", "                y0=int(min(ys)*scale); y1=int(max(ys)*scale)\n", "                x0=max(0,min(W-1,x0)); x1=max(0,min(W-1,x1))\n", "                y0=max(0,min(H-1,y0)); y1=max(0,min(H-1,y1))\n", "                circ_hits[y0:y1,x0:x1]=1\n", "    vector['rect_hits']=rect_hits; vector['circ_hits']=circ_hits\n", "\n", "len(vector['text_boxes']), len(vector['image_boxes'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4) Vision proposals + 5-type classification"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import cv2, numpy as np, pandas as pd, math\n", "\n", "gray = cv2.cvtColor(page_bgr, cv2.COLOR_BGR2GRAY)\n", "edges = cv2.Canny(gray, 50, 150)\n", "dil = cv2.dilate(edges, cv2.getStructuringElement(cv2.MORPH_RECT,(5,5)), iterations=2)\n", "cnts,_ = cv2.findContours(dil, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n", "cands=[]\n", "for c in cnts:\n", "    x,y,w,h=cv2.boundingRect(c); area=w*h\n", "    if area>8000 and w>60 and h>60 and w<W*0.98 and h<H*0.98:\n", "        cands.append((x,y,w,h))\n", "\n", "def merge_xyxy(boxes, pad=8):\n", "    if not boxes: return []\n", "    boxes=[(x-pad,y-pad,x+w+pad,y+h+pad) for (x,y,w,h) in sorted(boxes)]\n", "    changed=True\n", "    while changed:\n", "        changed=False; new=[]\n", "        while boxes:\n", "            a=boxes.pop(0); ax0,ay0,ax1,ay1=a\n", "            merged=False\n", "            for i,b in enumerate(boxes):\n", "                bx0,by0,bx1,by1=b\n", "                if not (ax1<bx0 or bx1<ax0 or ay1<by0 or by1<ay0):\n", "                    a=(min(ax0,bx0),min(ay0,by0),max(ax1,bx1),max(ay1,by1))\n", "                    boxes.pop(i); changed=True; merged=True; break\n", "            new.append(a)\n", "        boxes=new\n", "    out=[]\n", "    for (x0,y0,x1,y1) in boxes:\n", "        out.append((max(0,x0),max(0,y0),min(W-1,x1),min(H-1,y1)))\n", "    return out\n", "\n", "regions = merge_xyxy(cands)\n", "\n", "def table_mask(gray):\n", "    thr=cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n", "    h=255-thr; v=255-thr\n", "    h_kernel=cv2.getStructuringElement(cv2.MORPH_RECT,(max(10,W//60),1))\n", "    v_kernel=cv2.getStructuringElement(cv2.MORPH_RECT,(1,max(10,H//60)))\n", "    h_lines=cv2.morphologyEx(h, cv2.MORPH_OPEN, h_kernel)\n", "    v_lines=cv2.morphologyEx(v, cv2.MORPH_OPEN, v_kernel)\n", "    return cv2.bitwise_and(h_lines, v_lines)\n", "\n", "def bar_score(roi):\n", "    g=cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY)\n", "    t=cv2.threshold(cv2.GaussianBlur(g,(3,3),0),0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n", "    if (t==0).sum()>(t==255).sum(): t=cv2.bitwise_not(t)\n", "    t=cv2.morphologyEx(t,cv2.MORPH_CLOSE,cv2.getStructuringElement(cv2.MORPH_RECT,(3,3)),iterations=1)\n", "    cnts,_=cv2.findContours(t,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n", "    bars=[]\n", "    for c in cnts:\n", "        x,y,w,h=cv2.boundingRect(c)\n", "        if h/max(1.0,w)>1.3 and w*h>200 and h>20: bars.append((x,y,w,h))\n", "    if len(bars)<3: return 0.0, bars\n", "    import numpy as np\n", "    bottoms=[y+h for (x,y,w,h) in bars]\n", "    std=np.std(bottoms) if len(bottoms)>1 else 999\n", "    return float(len(bars)/(1+std/5.0)), bars\n", "\n", "def pie_score(roi):\n", "    g=cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY)\n", "    g=cv2.medianBlur(g,5)\n", "    circles=cv2.HoughCircles(g,cv2.HOUGH_GRADIENT,dp=1.2,minDist=30,param1=120,param2=40,minRadius=20,maxRadius=0)\n", "    if circles is None: return 0.0,None,[]\n", "    import numpy as np\n", "    c=max(np.uint16(np.around(circles))[0], key=lambda z:z[2])\n", "    cx,cy,r=int(c[0]),int(c[1]),int(c[2])\n", "    edges=cv2.Canny(g,60,180)\n", "    lines=cv2.HoughLinesP(edges,1,np.pi/180,threshold=60,minLineLength=int(r*0.6),maxLineGap=10)\n", "    radials=[]\n", "    if lines is not None:\n", "        for l in lines[:,0,:]:\n", "            x1,y1,x2,y2=l\n", "            def dist_point_line(px,py,a,b):\n", "                ax,ay=a; bx,by=b\n", "                lab=math.hypot(bx-ax,by-ay)\n", "                if lab==0: return math.hypot(px-ax,py-ay)\n", "                t=max(0,min(1,((px-ax)*(bx-ax)+(py-ay)*(by-ay))/(lab*lab)))\n", "                qx=ax+t*(bx-ax); qy=ay+t*(by-ay)\n", "                return math.hypot(px-qx,py-qy)\n", "            if dist_point_line(cx,cy,(x1,y1),(x2,y2))<r*0.08:\n", "                radials.append((x1,y1,x2,y2))\n", "    score=1.0+0.3*len(radials)\n", "    return float(score),(cx,cy,r),radials\n", "\n", "tmask=table_mask(gray)\n", "tcnts,_=cv2.findContours(tmask,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n", "table_regions=[]\n", "for c in tcnts:\n", "    x,y,w,h=cv2.boundingRect(c)\n", "    if w*h>5000 and w>80 and h>60:\n", "        table_regions.append((x,y,x+w,y+h))\n", "\n", "# text coverage mask\n", "text_mask = np.zeros((H,W), dtype=np.uint8)\n", "for (x0,y0,x1,y1) in vector.get('text_boxes', []):\n", "    cv2.rectangle(text_mask,(x0,y0),(x1,y1),255,-1)\n", "\n", "rect_hits=vector.get('rect_hits'); circ_hits=vector.get('circ_hits')\n", "labels=[]\n", "for (x0,y0,x1,y1) in regions:\n", "    roi=page_bgr[y0:y1,x0:x1]\n", "    # table overlap check\n", "    is_table=False\n", "    for (tx0,ty0,tx1,ty1) in table_regions:\n", "        if not (x1<tx0 or tx1<x0 or y1<ty0 or ty1<y0):\n", "            iw=min(x1,tx1)-max(x0,tx0); ih=min(y1,ty1)-max(y0,ty0)\n", "            if iw>10 and ih>10: is_table=True; break\n", "    if is_table:\n", "        label='table'\n", "    else:\n", "        bs,_=bar_score(roi); ps,_,_=pie_score(roi)\n", "        tr = text_mask[y0:y1,x0:x1].mean()/255.0 if (y1-y0)*(x1-x0)>0 else 0.0\n", "        if tr>0.3:\n", "            label='text'\n", "        else:\n", "            rsum=int(rect_hits[y0:y1,x0:x1].sum()) if rect_hits is not None else 0\n", "            csum=int(circ_hits[y0:y1,x0:x1].sum()) if circ_hits is not None else 0\n", "            if ps >= max(1.2, bs*1.3) or (csum>rsum and csum>1000):\n", "                label='pie_chart'\n", "            elif bs >= max(1.0, ps*1.2) or (rsum>csum and rsum>1000):\n", "                label='bar_chart'\n", "            else:\n", "                label='image_other'\n", "    labels.append({'x0':x0,'y0':y0,'x1':x1,'y1':y1,'w':x1-x0,'h':y1-y0,'label':label})\n", "\n", "regions_df = pd.DataFrame(labels)\n", "REGIONS_CSV = OUT_DIR / 'regions_5types.csv'\n", "regions_df.to_csv(REGIONS_CSV, index=False)\n", "REGIONS_CSV, regions_df['label'].value_counts().to_dict()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5) Extractors per region type"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os, csv, pandas as pd, numpy as np, cv2\n", "from pathlib import Path\n", "EXTRACT_DIR = OUT_DIR / 'extracts'\n", "EXTRACT_DIR.mkdir(exist_ok=True)\n", "\n", "# --- Utility: crop save ---\n", "def save_crop(label, idx, x0,y0,x1,y1):\n", "    crop = page_bgr[y0:y1, x0:x1]\n", "    p = EXTRACT_DIR / f'{label}_{idx}.png'\n", "    cv2.imwrite(p.as_posix(), crop)\n", "    return p\n", "\n", "# --- TEXT extraction --- vector preferred, else OCR ---\n", "TEXT_DIR = EXTRACT_DIR / 'text'; TEXT_DIR.mkdir(exist_ok=True)\n", "import importlib\n", "if importlib.util.find_spec('pdfplumber') is not None:\n", "    import pdfplumber\n", "    with pdfplumber.open(PDF_PATH) as pdf:\n", "        page = pdf.pages[PAGE_INDEX]\n", "        full_text = page.extract_text(x_tolerance=1.5, y_tolerance=2) or ''\n", "else:\n", "    full_text = ''\n", "\n", "def extract_text_region(idx, x0,y0,x1,y1):\n", "    # Try vector sub-selection if we have words; else OCR on crop.\n", "    txt=''\n", "    if importlib.util.find_spec('pdfplumber') is not None:\n", "        with pdfplumber.open(PDF_PATH) as pdf:\n", "            page = pdf.pages[PAGE_INDEX]\n", "            # convert pixel bbox to PDF pts by dividing scale\n", "            sx,sy = 1/scale, 1/scale\n", "            bbox_pts = (x0*sx, y0*sy, x1*sx, y1*sy)\n", "            cropped = page.within_bbox(bbox_pts)\n", "            txt = cropped.extract_text(x_tolerance=1.5, y_tolerance=2) or ''\n", "    if not txt:\n", "        if importlib.util.find_spec('pytesseract') is not None:\n", "            import pytesseract\n", "            crop = page_bgr[y0:y1, x0:x1]\n", "            g = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n", "            g = cv2.threshold(g,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n", "            txt = pytesseract.image_to_string(g)\n", "    fp = TEXT_DIR / f'text_{idx}.txt'\n", "    with open(fp,'w',encoding='utf-8') as f:\n", "        f.write(txt or '')\n", "    return fp\n", "\n", "# --- TABLE extraction --- Camelot preferred, fallback OCR grouping ---\n", "TABLE_DIR = EXTRACT_DIR / 'tables'; TABLE_DIR.mkdir(exist_ok=True)\n", "def extract_table_region(idx, x0,y0,x1,y1):\n", "    # Try Camelot on full page first (indexed) and then crop OCR if not found.\n", "    # For per-region exact table, OCR fallback is used due to library constraints on cropping.\n", "    crop_p = save_crop('table', idx, x0,y0,x1,y1)\n", "    out_csv = TABLE_DIR / f'table_{idx}.csv'\n", "    rows=[]\n", "    try:\n", "        import pytesseract\n", "        crop = cv2.imread(str(crop_p))\n", "        g=cv2.cvtColor(crop,cv2.COLOR_BGR2GRAY)\n", "        g=cv2.threshold(g,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n", "        data=pytesseract.image_to_data(g, output_type=pytesseract.Output.DICT)\n", "        # naive row grouping by y\n", "        line_bins={}\n", "        for i,txt in enumerate(data['text']):\n", "            t=txt.strip()\n", "            if not t: continue\n", "            yy=data['top'][i]\n", "            key=round(yy/10)*10\n", "            line_bins.setdefault(key,[]).append((data['left'][i], t))\n", "        for _,cells in sorted(line_bins.items()):\n", "            rows.append([t for _,t in sorted(cells)])\n", "    except Exception as e:\n", "        rows=[['(table OCR failed)']]\n", "    with open(out_csv,'w',newline='',encoding='utf-8') as f:\n", "        writer=csv.writer(f); writer.writerows(rows)\n", "    return out_csv\n", "\n", "# --- BAR chart extraction --- detect bars, infer y mapping from tick OCR when possible ---\n", "BAR_DIR = EXTRACT_DIR / 'bar_charts'; BAR_DIR.mkdir(exist_ok=True)\n", "def ocr_numeric_ticks(roi, side='left', margin=40):\n", "    # Heuristic crop along left/right margin to find y-axis ticks\n", "    h,w = roi.shape[:2]\n", "    if side=='left': sub = roi[:, :min(margin, w)]\n", "    else:            sub = roi[:, max(0,w-margin):]\n", "    if importlib.util.find_spec('pytesseract') is None:\n", "        return []\n", "    import pytesseract\n", "    g=cv2.cvtColor(sub,cv2.COLOR_BGR2GRAY)\n", "    g=cv2.threshold(g,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n", "    data=pytesseract.image_to_data(g, output_type=pytesseract.Output.DICT, config='--psm 6')\n", "    ticks=[]\n", "    for i,txt in enumerate(data['text']):\n", "        s=txt.strip().replace(',','')\n", "        if s.replace('.','',1).isdigit():\n", "            y=data['top'][i]+data['height'][i]//2\n", "            if side!='left':\n", "                xoff = w-margin\n", "            else:\n", "                xoff = 0\n", "            ticks.append({'y': y, 'val': float(s)})\n", "    # dedupe by close y\n", "    ticks=sorted(ticks, key=lambda d:d['y'])\n", "    uniq=[]\n", "    for t in ticks:\n", "        if not uniq or abs(t['y']-uniq[-1]['y'])>6:\n", "            uniq.append(t)\n", "    return uniq\n", "\n", "def bars_from_roi(roi):\n", "    g=cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY)\n", "    t=cv2.threshold(cv2.GaussianBlur(g,(3,3),0),0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n", "    if (t==0).sum()>(t==255).sum(): t=cv2.bitwise_not(t)\n", "    t=cv2.morphologyEx(t,cv2.MORPH_CLOSE,cv2.getStructuringElement(cv2.MORPH_RECT,(3,3)),iterations=1)\n", "    cnts,_=cv2.findContours(t,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n", "    bars=[]\n", "    for c in cnts:\n", "        x,y,w,h=cv2.boundingRect(c)\n", "        if h/max(1.0,w)>1.3 and w*h>200 and h>20:\n", "            bars.append((x,y,w,h))\n", "    bars=sorted(bars,key=lambda b:b[0])\n", "    return bars\n", "\n", "def map_pixels_to_values(bars, ypix_baseline, ypix_top, yval_min, yval_max):\n", "    span=max(1, ypix_baseline-ypix_top)\n", "    out=[]\n", "    for i,(x,y,w,h) in enumerate(bars, start=1):\n", "        ratio=(ypix_baseline - y) / span\n", "        val = yval_min + ratio * (yval_max - yval_min)\n", "        out.append({'index':i,'x':x,'y_top':y,'w':w,'h_px':h,'value':val})\n", "    return pd.DataFrame(out)\n", "\n", "def extract_bar_region(idx, x0,y0,x1,y1):\n", "    crop = page_bgr[y0:y1, x0:x1]\n", "    bars = bars_from_roi(crop)\n", "    # try OCR for y ticks on left then right\n", "    ticks = ocr_numeric_ticks(crop,'left') or ocr_numeric_ticks(crop,'right')\n", "    if len(ticks)>=2:\n", "        # choose farthest apart\n", "        t1=ticks[0]; t2=ticks[-1]\n", "        ypix_baseline = max(t1['y'], t2['y'])\n", "        ypix_top      = min(t1['y'], t2['y'])\n", "        yval_min      = min(t1['val'], t2['val'])\n", "        yval_max      = max(t1['val'], t2['val'])\n", "        df = map_pixels_to_values(bars, ypix_baseline, ypix_top, yval_min, yval_max)\n", "        mapping = {'source':'ocr_ticks','ypix_baseline':ypix_baseline,'ypix_top':ypix_top,'yval_min':yval_min,'yval_max':yval_max}\n", "    else:\n", "        # Fallback: normalized 0..1 based on pixel height\n", "        if bars:\n", "            ypix_baseline = max(y+h for (x,y,w,h) in bars)\n", "            ypix_top = min(y for (x,y,w,h) in bars)\n", "        else:\n", "            ypix_baseline = (y1-y0)-5; ypix_top=5\n", "        df = map_pixels_to_values(bars, ypix_baseline, ypix_top, 0.0, 1.0)\n", "        mapping = {'source':'normalized','ypix_baseline':ypix_baseline,'ypix_top':ypix_top,'yval_min':0.0,'yval_max':1.0}\n", "    csv_path = BAR_DIR / f'bar_{idx}.csv'\n", "    df.to_csv(csv_path, index=False)\n", "    # Try x labels OCR directly below baseline\n", "    labels=[]\n", "    try:\n", "        import pytesseract\n", "        baseline = mapping['ypix_baseline']\n", "        lab_band = crop[min(crop.shape[0]-1, baseline+3): min(crop.shape[0], baseline+50), :]\n", "        g=cv2.cvtColor(lab_band,cv2.COLOR_BGR2GRAY)\n", "        g=cv2.threshold(g,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n", "        data=pytesseract.image_to_data(g, output_type=pytesseract.Output.DICT, config='--psm 6')\n", "        # assign near bar x centers\n", "        centers=[x+w//2 for (x,y,w,h) in bars]\n", "        assigned=['']*len(centers)\n", "        items=[]\n", "        for i,txt in enumerate(data['text']):\n", "            s=txt.strip()\n", "            if not s: continue\n", "            x=data['left'][i]; w=data['width'][i]\n", "            cx=x+w//2\n", "            items.append((cx,s))\n", "        items.sort()\n", "        for j,c in enumerate(centers):\n", "            # closest item by |cx-c|\n", "            if items:\n", "                ii=min(range(len(items)), key=lambda k: abs(items[k][0]-c))\n", "                assigned[j]=items[ii][1]\n", "        df['label']=assigned\n", "        df.to_csv(csv_path, index=False)\n", "    except Exception:\n", "        pass\n", "    # Recreate bar chart\n", "    import matplotlib.pyplot as plt\n", "    plt.figure(figsize=(8,5))\n", "    xs=df['label'].fillna('').replace('', pd.Series(range(1,len(df)+1))).astype(str)\n", "    plt.bar(xs, df['value'].astype(float).values)\n", "    plt.ylabel('Value')\n", "    plt.title(f'Bar chart {idx}')\n", "    plt.tight_layout()\n", "    png = BAR_DIR / f'bar_{idx}.png'\n", "    plt.savefig(png.as_posix(), dpi=200)\n", "    plt.show()\n", "    return csv_path, png, mapping\n", "\n", "# --- PIE chart extraction --- determine slice angles \u2192 percentages; try label OCR around circle ---\n", "PIE_DIR = EXTRACT_DIR / 'pie_charts'; PIE_DIR.mkdir(exist_ok=True)\n", "import math\n", "def pie_geometry(roi):\n", "    g=cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY)\n", "    g=cv2.medianBlur(g,5)\n", "    circles=cv2.HoughCircles(g,cv2.HOUGH_GRADIENT,dp=1.2,minDist=30,param1=120,param2=40,minRadius=20,maxRadius=0)\n", "    if circles is None:\n", "        return None\n", "    import numpy as np\n", "    c=max(np.uint16(np.around(circles))[0], key=lambda z:z[2])\n", "    return int(c[0]), int(c[1]), int(c[2])\n", "\n", "def pie_slices(roi, cx,cy,r):\n", "    edges=cv2.Canny(cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY),60,180)\n", "    lines=cv2.HoughLinesP(edges,1,np.pi/180,threshold=60,minLineLength=int(r*0.6),maxLineGap=10)\n", "    angles=[]\n", "    if lines is not None:\n", "        for l in lines[:,0,:]:\n", "            x1,y1,x2,y2 = l\n", "            # keep lines that pass near center\n", "            def dist_point_line(px,py,a,b):\n", "                ax,ay=a; bx,by=b\n", "                lab=math.hypot(bx-ax,by-ay)\n", "                if lab==0: return math.hypot(px-ax,py-ay)\n", "                t=max(0,min(1,((px-ax)*(bx-ax)+(py-ay)*(by-ay))/(lab*lab)))\n", "                qx=ax+t*(bx-ax); qy=ay+t*(by-ay)\n", "                return math.hypot(px-qx,py-qy)\n", "            if dist_point_line(cx,cy,(x1,y1),(x2,y2)) < r*0.08:\n", "                ang=math.degrees(math.atan2(y1-cy, x1-cx))\n", "                angles.append(ang)\n", "                ang=math.degrees(math.atan2(y2-cy, x2-cx))\n", "                angles.append(ang)\n", "    # normalize and sort\n", "    angles=[(a+360)%360 for a in angles]\n", "    angles=sorted(list(set(int(round(a)) for a in angles)))\n", "    if len(angles)<3:\n", "        return []\n", "    # get consecutive differences (wraparound)\n", "    diffs=[]\n", "    for i in range(len(angles)):\n", "        a1=angles[i]; a2=angles[(i+1)%len(angles)]\n", "        d=(a2-a1) % 360\n", "        diffs.append(d)\n", "    total=sum(diffs)\n", "    return [{'slice':i+1,'angle_deg':d,'pct':(d/total*100.0 if total else 0)} for i,d in enumerate(diffs)]\n", "\n", "def extract_pie_region(idx, x0,y0,x1,y1):\n", "    crop = page_bgr[y0:y1, x0:x1]\n", "    geom = pie_geometry(crop)\n", "    if geom is None:\n", "        data = [{'slice':1,'angle_deg':360,'pct':100.0}]\n", "    else:\n", "        cx,cy,r = geom\n", "        data = pie_slices(crop, cx,cy,r) or [{'slice':1,'angle_deg':360,'pct':100.0}]\n", "    df = pd.DataFrame(data)\n", "    csv_path = PIE_DIR / f'pie_{idx}.csv'\n", "    df.to_csv(csv_path, index=False)\n", "    # Recreate pie chart\n", "    import matplotlib.pyplot as plt\n", "    plt.figure(figsize=(5,5))\n", "    plt.pie(df['pct'].astype(float).values, labels=df['slice'].astype(str).values, autopct='%1.1f%%')\n", "    plt.title(f'Pie chart {idx}')\n", "    plt.tight_layout()\n", "    png = PIE_DIR / f'pie_{idx}.png'\n", "    plt.savefig(png.as_posix(), dpi=200)\n", "    plt.show()\n", "    return csv_path, png\n", "\n", "# --- IMAGE regions --- simply export crops ---\n", "IMG_DIR = EXTRACT_DIR / 'images'; IMG_DIR.mkdir(exist_ok=True)\n", "def extract_image_region(idx, x0,y0,x1,y1):\n", "    return save_crop('image', idx, x0,y0,x1,y1)\n", "\n", "# Main extraction loop\n", "outputs = []\n", "for i,row in regions_df.iterrows():\n", "    x0,y0,x1,y1 = map(int, (row.x0,row.y0,row.x1,row.y1))\n", "    label=row.label\n", "    if label=='text':\n", "        fp = extract_text_region(i+1, x0,y0,x1,y1)\n", "        outputs.append({'type':'text','index':i+1,'path':str(fp)})\n", "    elif label=='table':\n", "        fp = extract_table_region(i+1, x0,y0,x1,y1)\n", "        outputs.append({'type':'table','index':i+1,'path':str(fp)})\n", "    elif label=='bar_chart':\n", "        csvp, pngp, mapping = extract_bar_region(i+1, x0,y0,x1,y1)\n", "        outputs.append({'type':'bar_chart','index':i+1,'csv':str(csvp),'png':str(pngp),'mapping':mapping})\n", "    elif label=='pie_chart':\n", "        csvp, pngp = extract_pie_region(i+1, x0,y0,x1,y1)\n", "        outputs.append({'type':'pie_chart','index':i+1,'csv':str(csvp),'png':str(pngp)})\n", "    else:\n", "        p = extract_image_region(i+1, x0,y0,x1,y1)\n", "        outputs.append({'type':'image_other','index':i+1,'path':str(p)})\n", "\n", "OUT_JSON = OUT_DIR / 'extraction_summary.json'\n", "import json\n", "with open(OUT_JSON,'w',encoding='utf-8') as f:\n", "    json.dump(outputs, f, ensure_ascii=False, indent=2)\n", "OUT_JSON, len(outputs)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6) Annotated preview + crops"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["annot = page_bgr.copy()\n", "colors = {\n", "    'text': (255,0,0),        # BGR colors for OpenCV draw only\n", "    'table': (0,255,255),\n", "    'bar_chart': (0,255,0),\n", "    'pie_chart': (0,165,255),\n", "    'image_other': (0,0,255)\n", "}\n", "for _,r in regions_df.iterrows():\n", "    x0,y0,x1,y1 = int(r.x0),int(r.y0),int(r.x1),int(r.y1)\n", "    cv2.rectangle(annot,(x0,y0),(x1,y1),colors.get(r.label,(255,255,255)),2)\n", "    cv2.putText(annot,r.label,(x0,max(0,y0-5)),cv2.FONT_HERSHEY_SIMPLEX,0.6,colors.get(r.label,(255,255,255)),2,cv2.LINE_AA)\n", "PREVIEW = OUT_DIR / 'preview_5types.png'\n", "cv2.imwrite(PREVIEW.as_posix(), annot)\n", "PREVIEW"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7) Optional: Build a PPTX with extracts (text snippet, first table, first bar/pie)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import importlib\n", "if importlib.util.find_spec('pptx') is None:\n", "    print('python-pptx not installed; skipping PPT build.')\n", "else:\n", "    from pptx import Presentation\n", "    from pptx.util import Inches\n", "    import pandas as pd, json\n", "    prs = Presentation()\n", "    # Title\n", "    slide = prs.slides.add_slide(prs.slide_layouts[0])\n", "    slide.shapes.title.text = 'PDF Extract & Recreate Summary'\n", "    slide.placeholders[1].text = f'Page {PAGE_INDEX+1} \u2014 {PDF_PATH.name}'\n", "    # Text slide (first)\n", "    texts=[o for o in outputs if o['type']=='text']\n", "    if texts:\n", "        slide2 = prs.slides.add_slide(prs.slide_layouts[1])\n", "        slide2.shapes.title.text = 'Text Extract (snippet)'\n", "        with open(texts[0]['path'],'r',encoding='utf-8') as f:\n", "            snip=f.read()[:2000]\n", "        slide2.placeholders[1].text = snip\n", "    # Table slide (first)\n", "    tables=[o for o in outputs if o['type']=='table']\n", "    if tables:\n", "        import pandas as pd\n", "        df = pd.read_csv(tables[0]['path'], header=None)\n", "        slide3 = prs.slides.add_slide(prs.slide_layouts[6])\n", "        rows, cols = df.shape\n", "        table = slide3.shapes.add_table(rows+1, cols, Inches(0.5), Inches(1), Inches(9), Inches(5)).table\n", "        for j in range(cols):\n", "            table.cell(0,j).text = f'Col {j+1}'\n", "        for i in range(rows):\n", "            for j in range(cols):\n", "                table.cell(i+1,j).text = str(df.iat[i,j])\n", "    # Bar chart slide\n", "    bars=[o for o in outputs if o['type']=='bar_chart']\n", "    if bars:\n", "        slide4 = prs.slides.add_slide(prs.slide_layouts[6])\n", "        slide4.shapes.add_picture(bars[0]['png'], Inches(1), Inches(1), width=Inches(8))\n", "    # Pie chart slide\n", "    pies=[o for o in outputs if o['type']=='pie_chart']\n", "    if pies:\n", "        slide5 = prs.slides.add_slide(prs.slide_layouts[6])\n", "        slide5.shapes.add_picture(pies[0]['png'], Inches(2.5), Inches(1.5), width=Inches(5))\n", "    PPTX_PATH = OUT_DIR / 'extract_recreate_summary.pptx'\n", "    prs.save(PPTX_PATH.as_posix())\n", "    PPTX_PATH"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 8) Notes\n", "- If bar tick OCR fails, the bar values will be **normalized 0\u20131**. You can set axis min/max manually by editing the `extract_bar_region` function.\n", "- Pie slice detection uses radial line detection; for very stylized pies, consider legend-percentage OCR.\n", "- Tables via Camelot are more accurate on vector PDFs; for scanned tables, OCR grouping is a fallback.\n", "- Run one page at a time; to process multiple pages, loop over `PAGE_INDEX` and aggregate outputs."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}